<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Monitoring :: SUSE CaaS Platform Documentation</title>
    <meta name="generator" content="Antora 2.0.0">
    <link rel="stylesheet" href="../../../_/css/site.css">
<link rel="stylesheet" href="../../../_/css/suse.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
<!-- fetched from https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css -->
<link rel="icon" href="../../../_/img/favicon.ico" type="image/x-icon">
  </head>
  <body class="article">
<header class="header" role="banner">
  <nav class="navbar">
    <div class="navbar-brand">
      <div class="navbar-logo">
        <img class="logo" src="../../../_/img/suse_logo_reverse.png" />
      </div>
      <div class="navbar-item">
        <a href="https://r0ckarong.github.io">SUSE CaaS Platform</a>
        <span class="separator">//</span>
        <a href="../../..">Documentation</a>
      </div>
      <div class="navbar-item">
        <input id="search-input" type="text" placeholder="Search docs">
      </div>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable">
          <div class="navbar-link">Projects</div>
          <div class="navbar-dropdown">
            <div class="navbar-item"><strong>Resources</strong></div>
            <a class="navbar-item" href="https://github.com/SUSE/doc-caasp/tree/antora">Repository</a>
            <a class="navbar-item" href="https://github.com/SUSE/doc-caasp/issues">Issue Tracker</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="main-wrapper">
<div class="navigation-container" data-component="suse-caasp" data-version="v4-beta1">
  <aside class="navigation">
    <div class="panels">
<div class="navigation-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">SUSE CaaS Platform</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-toggle"></button>
    <a class="nav-link" href="../quickstart/quick_intro.html">Quickstart Guide</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../quickstart/quick_system_requirements.html">System Requirements</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../quickstart/quick_install.html">Installation and Configuring Nodes</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../quickstart/quick_configuration.html">Node Configuration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-toggle"></button>
    <a class="nav-link" href="admin_intro.html">Administration Guide</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_security.html">Security</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_administration.html">Administration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_software.html">Software Management</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="admin_monitoring.html">Monitoring</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_logging.html">Logging</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_misc.html">Miscellaenous Configuration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_integration_ses.html">SES Integration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="admin_troubleshooting.html">Troubleshooting</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-toggle"></button>
    <a class="nav-link" href="../deployment/deployment_intro.html">Deployment Guide</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_about.html">About Deployment Guide</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_scenarios.html">Deployment Scenarios</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_sysreqs.html">System Requirements</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_preparation.html">Preparing The Installation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_installing_nodes.html">Installing and Configuring Nodes</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_configuration.html">Node Configuration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../deployment/deployment_appendix.html">Appendix</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="navigation-explore" data-panel="explore">
  <div class="context">
    <span class="title">SUSE CaaS Platform</span>
    <span class="version">v4-beta1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">SUSE CaaS Platform</span>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">v4-beta1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
  <main class="main">
<div class="toolbar" role="navigation">
  <button class="navigation-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="crumbs" aria-label="breadcrumbs">
  <ul>
    <li class="crumb"><a href="../index.html">SUSE CaaS Platform</a></li>
    <li class="crumb"><a href="admin_intro.html">Administration Guide</a></li>
    <li class="crumb"><a href="admin_monitoring.html">Monitoring</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="file:///home/mnapp/mydata/software/SUSE/doc-caasp/modules/administration/pages/admin_monitoring.adoc">Edit this Page</a></div>
</div>
<article class="doc">
<h1>Monitoring</h1>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_sec.admin.monitoring.stack">1. Monitoring Stack On {kube}</a>
<ul class="sectlevel2">
<li><a href="#_prerequisites">1.1. Prerequisites</a></li>
<li><a href="#_nginx_ingress_controller">1.2. NGINX Ingress Controller</a></li>
<li><a href="#_tls">1.3. TLS</a></li>
<li><a href="#_prometheus">1.4. Prometheus</a></li>
<li><a href="#_alertmanager_configuration">1.5. Alertmanager Configuration Example</a></li>
<li><a href="#_grafana">1.6. Grafana</a></li>
</ul>
</li>
<li><a href="#_sec.admin.monitoring.health">2. Health Checking</a>
<ul class="sectlevel2">
<li><a href="#_sec.admin.monitoring.health.cluster">2.1. Cluster Health Checks</a></li>
<li><a href="#_sec.admin.monitoring.health.node">2.2. Node Health Checks</a></li>
<li><a href="#_sec.admin.monitoring.health.service">2.3. Service/Application Health Checks</a></li>
<li><a href="#_sec.admin.monitoring.health.general">2.4. General Health Checks</a></li>
</ul>
</li>
</ul>
</div>
<div class="sect1">
<h2 id="_sec.admin.monitoring.stack"><a class="anchor" href="#_sec.admin.monitoring.stack"></a>1. Monitoring Stack On {kube}</h2>
<div class="sectionbody">
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="title">Monitoring Example</div>
<div class="paragraph">
<p>This is not an officially supported recommendation and does not claim complete coverage of any use case in a production environment.</p>
</div>
<div class="paragraph">
<p>The described monitoring approach in this document is a generalized example of one way of monitoring a {productname}
cluster.</p>
</div>
<div class="paragraph">
<p>Please apply best practices to develop your own monitoring approach using the described examples and available health checking endpoints.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This document aims to describe monitoring in a {kube}
environment.</p>
</div>
<div class="paragraph">
<p>The monitoring stack consists of a metrics server, a visualization platform, and an ingress controller for authentication.</p>
</div>
<div class="paragraph">
<p><strong>Prometheus Server &amp; Alertmanager</strong></p>
</div>
<div class="paragraph">
<p>Prometheus is an open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.</p>
</div>
<div class="paragraph">
<p><a href="https://prometheus.io/docs/alerting/alertmanager/">Prometheus
   Alertmanager</a> handles client alerts, sanitizes duplicates and noise and routes them to configuratble receivers.</p>
</div>
<div class="paragraph">
<p><strong>Grafana</strong></p>
</div>
<div class="paragraph">
<p>Grafana is an open-source system for querying, analysing and visualizing metrics.</p>
</div>
<div class="paragraph">
<p><strong>NGINX Ingress Controller</strong></p>
</div>
<div class="paragraph">
<p>Deploying NGINX Ingress Controller allows us to provide TLS termination to our services and to provide basic authentication to the Prometheus Expression browser/API.</p>
</div>
<div class="sect2">
<h3 id="_prerequisites"><a class="anchor" href="#_prerequisites"></a>1.1. Prerequisites</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Monitoring namespace</p>
<div class="paragraph">
<p>We will deploy our monitoring stack in its own namespace and therefore create one.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl create namespace monitoring``</pre>
</div>
</div>
</li>
<li>
<p>Create DNS entries</p>
<div class="paragraph">
<p>In this example, we will use a worker node with IP <code>192.168.1.113</code> to expose our services.</p>
</div>
<div class="paragraph">
<p>You should configure proper DNS names in any production environment.
These values are only for example purposes.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>monitoring.example.com                      IN  A       192.168.1.113
prometheus.example.com                      IN  CNAME   monitoring.example.com
prometheus-alertmanager.example.com         IN  CNAME   monitoring.example.com
grafana.example.com                         IN  CNAME   monitoring.example.com</pre>
</div>
</div>
<div class="paragraph">
<p>Or add this entry to /etc/hosts</p>
</div>
<div class="listingblock">
<div class="content">
<pre>192.168.1.113 prometheus.example.com prometheus-alertmanager.example.com grafana.example.com</pre>
</div>
</div>
</li>
<li>
<p>Create certificates</p>
<div class="paragraph">
<p>You will need SSL certificates for the shared resources.
If you are deploying in a pre-defined network environment, please get proper certificates from your network administrator.
In this example, the domains are named after the components they represent. <code>prometheus.example.com</code>, <code>prometheus-alertmanager.example.com</code> and <code>grafana.example.com</code></p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_nginx_ingress_controller"><a class="anchor" href="#_nginx_ingress_controller"></a>1.2. NGINX Ingress Controller</h3>
<div class="olist arabic">
<div class="title">Procedure: Configure And Deploy NGINX Ingress Controller</div>
<ol class="arabic">
<li>
<p>Choose which networking configuration the Ingress controller should have. Create a file <code class="path">nginx-ingress-config-values.yaml</code> with one of the following examples as content.</p>
<div class="ulist">
<ul>
<li>
<p><strong>NodePort</strong>: The services will be publicly exposed on each node of the cluster, including master nodes, at port <code>30080</code> for <code>HTTP</code> and <code>30443</code> for <code>HTTPS</code>.</p>
<div class="listingblock">
<div class="content">
<pre># Enable the creation of pod security policy
podSecurityPolicy:
  enabled: true

# Create a specific service account
serviceAccount:
  create: true
  name: nginx-ingress

# Publish services on port HTTP/30080
# Publish services on port HTTPS/30443
# These services are exposed on each node
controller:
  service:
    type: NodePort
    nodePorts:
      http: 30080
      https: 30443</pre>
</div>
</div>
</li>
<li>
<p><strong>ClusterIP with external IP(s)</strong>: The services will be exposed on specific nodes of the cluster, at port <code>80</code> for <code>HTTP</code> and port <code>443</code> for <code>HTTPS</code>.</p>
<div class="listingblock">
<div class="content">
<pre># Enable the creation of pod security policy
podSecurityPolicy:
  enabled: true

# Create a specific service account
serviceAccount:
  create: true
  name: nginx-ingress

# Publish services on port HTTP/80
# Publish services on port HTTPS/443
# These services are exposed on the node with IP 192.168.1.113
controller:
  service:
    externalIPs:
      - 192.168.1.113</pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Deploy the upstream helm chart and pass along our configuration values file.</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``helm install --name nginx-ingress stable/nginx-ingress \
--namespace monitoring \
--values nginx-ingress-config-values.yaml``</pre>
</div>
</div>
<div class="paragraph">
<p>The result should be two running pods:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl -n monitoring get po`` NAME                                             READY     STATUS    RESTARTS   AGE
nginx-ingress-controller-74cffccfc-p8xbb         1/1       Running   0          4s
nginx-ingress-default-backend-6b9b546dc8-mfkjk   1/1       Running   0          4s</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_tls"><a class="anchor" href="#_tls"></a>1.3. TLS</h3>
<div class="paragraph">
<p>You must configure your certificates for the components as secrets in {kube}
.
Get certificates from your local certificate authority.
In this example we are using a single certificate shared by the components <code>prometheus.example.com</code>, <code>prometheus-alertmanager.example.com</code> and <code>grafana.example.com</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Create Individual Secrets For Components</div>
<div class="paragraph">
<p>Should you choose to secure each service with an individual certificate, you must repeat the step below for each component and adjust the name for the individual secret each time.</p>
</div>
<div class="paragraph">
<p>In this example the name is <code>monitoring-tls</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="title">Note Down Secret Names For Configuration</div>
<div class="paragraph">
<p>Please note down the names of the secrets you have created.
Later configuration steps require secret names to be specified.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<div class="title">Procedure: Create TLS secrets in {kube}</div>
<ol class="arabic">
<li>
<p></p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl create -n monitoring secret tls monitoring-tls  \
--key  ./monitoring.key \
--cert ./monitoring.crt``</pre>
</div>
</div>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_using_self_signed_certificates_optional"><a class="anchor" href="#_using_self_signed_certificates_optional"></a>1.3.1. Using Self-signed Certificates (optional)</h4>
<div class="paragraph">
<p>In some cases you will want to create self-signed certificates for testing of the stack.
This is not recommended.
If you are using proper CA signed certificates, you must skip this entirely.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure: Create Self-signed Certificates</div>
<ol class="arabic">
<li>
<p></p>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Do not use self-signed certificates in production environments.
There is severe risk of Man-in-the-middle attacks.
Use proper certificates signed by your CA.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Create a file <em>openssl.conf</em> with the appropriate values</p>
<div class="listingblock">
<div class="content">
<pre>[req]
distinguished_name = req_distinguished_name
req_extensions = v3_req
default_md = sha256
default_bits = 4096
prompt=no

[req_distinguished_name]
C = CZ
ST = CZ
L = Prague
O = example
OU = monitoring
CN = example.com
emailAddress = admin@example.com

[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = keyEncipherment, dataEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names

[alt_names]
DNS.1 = prometheus.example.com
DNS.2 = prometheus-alertmanager.example.com
DNS.3 = grafana.example.com</pre>
</div>
</div>
<div class="paragraph">
<p>This certificate uses Subject Alternative Names so it can be used for Prometheus and Grafana.</p>
</div>
</li>
<li>
<p>Generate certificate</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``openssl req -x509 -nodes -days 365 -newkey rsa:4096 \
-keyout ./monitoring.key -out ./monitoring.crt \
-config ./openssl.conf -extensions 'v3_req'``</pre>
</div>
</div>
</li>
<li>
<p>Add TLS secret to {kube}</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl create -n monitoring secret tls monitoring-tls  \
--key  ./monitoring.key \
--cert ./monitoring.crt``</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_prometheus"><a class="anchor" href="#_prometheus"></a>1.4. Prometheus</h3>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Prometheus Pushgateway</div>
<div class="paragraph">
<p>Deploying Prometheus <a href="https://prometheus.io/docs/practices/pushing/">Pushgateway</a> is out of the scope of this document.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Configure Authentication</p>
<div class="paragraph">
<p>We need to create a <code>basic-auth</code> secret so the NGINX Ingress Controller can perform authentication.</p>
</div>
<div class="paragraph">
<p>Install <code class="command">htpasswd</code> on your local workstation</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.sudo}``zypper in apache2-utils``</pre>
</div>
</div>
<div class="paragraph">
<p>Create the secret file <code class="path">auth</code></p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
It is very important that the filename is <code class="path">auth</code>
.
During creation, a key in the configuration containing the secret is created that is named after the used filename.
The ingress controller will expect a key named <code>auth</code>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre>htpasswd -c auth admin
New password:
Re-type new password:
Adding password for user admin</pre>
</div>
</div>
<div class="paragraph">
<p>Create secret in {kube}</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl create secret generic -n monitoring prometheus-basic-auth --from-file=auth``</pre>
</div>
</div>
</li>
<li>
<p>Create a configuration file <code class="path">prometheus-config-values.yaml</code></p>
<div class="paragraph">
<p>We need to configure the storage for our deployment.
Choose among the options and uncomment the line in the config file.
In production environments you must configure persistent storage.
<strong> Use an existing <code>PersistentVolumeClaim</code>
</strong> Use a <code>StorageClass</code> (preferred)</p>
</div>
<div class="listingblock">
<div class="content">
<pre># Alertmanager configuration
alertmanager:
  enabled: true
  ingress:
    enabled: true
    hosts:
    -  prometheus-alertmanager.example.com
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    tls:
      - hosts:
        - prometheus-alertmanager.example.com
        secretName: monitoring-tls
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 2Gi
    size: 2Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## AlertManager is configured through alertmanager.yml. This file and any others
## listed in alertmanagerFiles will be mounted into the alertmanager pod.
## See configuration options https://prometheus.io/docs/alerting/configuration/
#alertmanagerFiles:
#  alertmanager.yml:

# Create a specific service account
serviceAccounts:
  nodeExporter:
    name: prometheus-node-exporter

# Allow scheduling of node-exporter on master nodes
nodeExporter:
  hostNetwork: false
  hostPID: false
  podSecurityPolicy:
    enabled: true
    annotations:
      seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default'
      apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'
      seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'
      apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'
  tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule

# Disable Pushgateway
pushgateway:
  enabled: false

# Prometheus configuration
server:
  ingress:
    enabled: true
    hosts:
    - prometheus.example.com
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    tls:
      - hosts:
        - prometheus.example.com
        secretName: monitoring-tls
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 8Gi
    size: 8Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## Prometheus is configured through prometheus.yml. This file and any others
## listed in serverFiles will be mounted into the server pod.
## See configuration options
## https://prometheus.io/docs/prometheus/latest/configuration/configuration/
#serverFiles:
#  prometheus.yml:</pre>
</div>
</div>
</li>
<li>
<p>Deploy the upstream helm chart and pass our configuration values file.</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``helm install --name prometheus stable/prometheus \
--namespace monitoring \
--values prometheus-config-values.yaml``</pre>
</div>
</div>
<div class="paragraph">
<p>There need to be 3 pods running (3 node-exporter pods because we have 3 nodes).</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}kubectl -n monitoring get po | grep prometheus
NAME                                             READY     STATUS    RESTARTS   AGE
prometheus-alertmanager-5487596d54-kcdd6         2/2       Running   0          2m
prometheus-kube-state-metrics-566669df8c-krblx   1/1       Running   0          2m
prometheus-node-exporter-jnc5w                   1/1       Running   0          2m
prometheus-node-exporter-qfwp9                   1/1       Running   0          2m
prometheus-node-exporter-sc4ls                   1/1       Running   0          2m
prometheus-server-6488f6c4cd-5n9w8               2/2       Running   0          2m</pre>
</div>
</div>
</li>
<li>
<p>At this stage, the Prometheus Expression browser/API should be accessible, depending on your network configuration at <code><a href="https://prometheus.example.com" class="bare">https://prometheus.example.com</a></code> or <code><a href="https://prometheus.example.com:30443" class="bare">https://prometheus.example.com:30443</a></code>.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_alertmanager_configuration"><a class="anchor" href="#_alertmanager_configuration"></a>1.5. Alertmanager Configuration Example</h3>
<div class="paragraph">
<p>The configuration sets one "receiver" to get notified by email when a node meets one of these conditions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Node is unschedulable</p>
</li>
<li>
<p>Node runs out of disk space</p>
</li>
<li>
<p>Node has memory pressure</p>
</li>
<li>
<p>Node has disk pressure</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The first two are critical because the node can not accept new pods, the last two are just warnings.</p>
</div>
<div class="paragraph">
<p>The Alertmanager configuration can be added to <code class="path">prometheus-config-values.yaml</code>
 by adding the <code>alertmanagerFiles</code> section.</p>
</div>
<div class="paragraph">
<p>For more information on how to configure Alertmanager, refer to <a href="https://prometheus.io/docs/alerting/configuration">Prometheus:
    Alerting - Configuration</a>.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure: Configuring Alertmanager</div>
<ol class="arabic">
<li>
<p>Add the <code>alertmanagerFiles</code> section to your Prometheus configuration.</p>
<div class="listingblock">
<div class="content">
<pre>alertmanagerFiles:
  alertmanager.yml:
    global:
      # The smarthost and SMTP sender used for mail notifications.
      smtp_from: alertmanager@example.com
      smtp_smarthost: smtp.example.com:587
      smtp_auth_username: admin@example.com
      smtp_auth_password: &lt;password&gt;
      smtp_require_tls: true

    route:
      # The labels by which incoming alerts are grouped together.
      group_by: ['node']

      # When a new group of alerts is created by an incoming alert, wait at
      # least 'group_wait' to send the initial notification.
      # This way ensures that you get multiple alerts for the same group that start
      # firing shortly after another are batched together on the first
      # notification.
      group_wait: 30s

      # When the first notification was sent, wait 'group_interval' to send a batch
      # of new alerts that started firing for that group.
      group_interval: 5m

      # If an alert has successfully been sent, wait 'repeat_interval' to
      # resend them.
      repeat_interval: 3h

      # A default receiver
      receiver: admin-example

    receivers:
    - name: 'admin-example'
      email_configs:
      - to: 'admin@example.com'</pre>
</div>
</div>
</li>
<li>
<p>Replace the empty set of rules <code>rules: {}</code> in the <code>serverFiles</code> section of the configuration file.</p>
<div class="paragraph">
<p>For more information on how to configure alerts, refer to: <a href="https://prometheus.io/docs/alerting/notification_examples/">Prometheus:
Alerting - Notification Template Examples</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre>serverFiles:
  alerts: {}
  rules:
    groups:
    - name: caasp.node.rules
      rules:
      - alert: NodeIsNotReady
        expr: kube_node_status_condition{condition="Ready",status="false"} == 1
        for: 1m
        labels:
          severity: critical
        annotations:
          description: '{{ $labels.node }} is not ready'
      - alert: NodeIsOutOfDisk
        expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
        labels:
          severity: critical
        annotations:
          description: '{{ $labels.node }} has insufficient free disk space'
      - alert: NodeHasDiskPressure
        expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        labels:
          severity: warning
        annotations:
          description: '{{ $labels.node }} has insufficient available disk space'
      - alert: NodeHasInsufficientMemory
        expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        labels:
          severity: warning
        annotations:
          description: '{{ $labels.node }} has insufficient available memory'</pre>
</div>
</div>
</li>
<li>
<p>You should now be able to see you AlertManager at <a href="https://prometheus-alertmanager.example.com/" class="bare">https://prometheus-alertmanager.example.com/</a>.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_grafana"><a class="anchor" href="#_grafana"></a>1.6. Grafana</h3>
<div class="paragraph">
<p>Starting from Grafana 5.0, it is possible to dynamically provision the data sources and dashbords via files.
In {kube}
, these files are provided via the utilization of <code>ConfigMap</code>, editing a <code>ConfigMap</code> will result by the modification of the configuration without having to delete/recreate the pod.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure: Configuring Grafana</div>
<ol class="arabic">
<li>
<p>Configure provisoning</p>
<div class="paragraph">
<p>Create the default datasource configuration file <em>grafana-datasources.yaml</em> which point to our Prometheus server</p>
</div>
<div class="listingblock">
<div class="content">
<pre>---
kind: ConfigMap
apiVersion: v1
metadata:
  name: grafana-datasources
  namespace: monitoring
  labels:
     grafana_datasource: "1"
data:
  datasource.yaml: |-
    apiVersion: 1
    deleteDatasources:
      - name: Prometheus
        orgId: 1
    datasources:
    - name: Prometheus
      type: prometheus
      url: http://prometheus-server.monitoring.svc.cluster.local:80
      access: proxy
      orgId: 1
      isDefault: true</pre>
</div>
</div>
</li>
<li>
<p>Create the ConfigMap in {kube}</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl create -f grafana-datasources.yaml``</pre>
</div>
</div>
</li>
<li>
<p>Configure storage for the deployment</p>
<div class="paragraph">
<p>Choose among the options and uncomment the line in the config file.
In production environments you must configure persistent storage.
<strong> Use an existing PersistentVolumeClaim
</strong> Use a StorageClass (preferred)
** Create a file <em>grafana-config-values.yaml</em> with the appropriate values</p>
</div>
<div class="listingblock">
<div class="content">
<pre># Configure admin password
adminPassword: &lt;password&gt;

# Ingress configuration
ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - grafana.example.com
  tls:
    - hosts:
      - grafana.example.com
      secretName: monitoring-tls

# Configure persistent storage
persistence:
  enabled: true
  accessModes:
    - ReadWriteOnce
  ## Use a StorageClass
  storageClassName: my-storage-class
  ## Create a PersistentVolumeClaim of 10Gi
  size: 10Gi
  ## Use an existing PersistentVolumeClaim (my-pvc)
  #existingClaim: my-pvc

# Enable sidecar for provisioning
sidecar:
  datasources:
    enabled: true
    label: grafana_datasource
  dashboards:
    enabled: true
    label: grafana_dashboard</pre>
</div>
</div>
</li>
<li>
<p>Deploy the upstream helm chart and pass our configuration values file</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``helm install --name grafana stable/grafana \
--namespace monitoring \
--values grafana-config-values.yaml``</pre>
</div>
</div>
</li>
<li>
<p>The result should be a running Grafana pod</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl -n monitoring get po | grep grafana`` NAME                                             READY     STATUS    RESTARTS   AGE
grafana-dbf7ddb7d-fxg6d                          3/3       Running   0          2m</pre>
</div>
</div>
<div class="paragraph">
<p>At this stage, Grafana should be accessible, depending on your network configuration at <code><a href="https://grafana.example.com" class="bare">https://grafana.example.com</a></code> or <code><a href="https://grafana.example.com:30443" class="bare">https://grafana.example.com:30443</a></code></p>
</div>
</li>
<li>
<p>Now you can deploy an existing <a href="https://grafana.com/dashboards">Grafana dashboard</a> or build your own.</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_adding_grafana_dashboards"><a class="anchor" href="#_adding_grafana_dashboards"></a>1.6.1. Adding Grafana Dashboards</h4>
<div class="paragraph">
<p>There are two ways to add dashboards to Grafana:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Deploy an existing dashboard from <a href="https://grafana.com/dashboards">grafana.com</a></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Open the deployed Grafana in your browser and log in.</p>
</li>
<li>
<p>On the home page of Grafana, hover your mousecursor over the menu:+[] button on the left sidebar and click on the <b class="menuref">import</b> menuitem.</p>
</li>
<li>
<p>Select an existing dashboard for your purpose from <a href="https://grafana.com/dashboards" class="bare">https://grafana.com/dashboards</a>. Copy the URL to the clipboard.</p>
</li>
<li>
<p>Paste the URL (for example) <code><a href="https://grafana.com/dashboards/3131" class="bare">https://grafana.com/dashboards/3131</a></code> into the first input field to import the "Kubernetes All Nodes" Grafana Dashboard. After pasting in the url, the view will change to another form.</p>
</li>
<li>
<p>Now select the "Prometheus" datasource in the <code>prometheus</code> field and click on the <b class="menuref">import</b> button.</p>
</li>
<li>
<p>The browser will redirect you to your newly created dashboard.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy a configuration file containing the dashboard definition.</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Create your dashboard defintion file as a <code>ConfigMap</code>, for example <code class="path">grafana-dashboards-caasp-cluster.yaml</code> .</p>
<div class="listingblock">
<div class="content">
<pre>---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards-caasp-cluster
  namespace: monitoring
  labels:
     grafana_dashboard: "1"
data:
  caasp-cluster.json: |-
    {
      "__inputs": [
        {
          "name": "DS_PROMETHEUS",
          "label": "Prometheus",
          "description": "",
          "type": "datasource",
          "pluginId": "prometheus",
          "pluginName": "Prometheus"
        }
      ],
      "__requires": [
        {
          "type": "grafana",
[...]
continues with definition of dashboard JSON
[...]</pre>
</div>
</div>
</li>
<li>
<p>Apply the <code>ConfigMap</code> to the cluster.</p>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl apply -f grafana-dashboards-caasp-cluster.yaml``</pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>You can find a couple of dashboard examples for {productname}
in the <a href="https://github.com/kubic-project/monitoring">Kubic project</a> on GitHub.
This repo provides dashboards to visualize {kube}
resources.</p>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_sec.admin.monitoring.health"><a class="anchor" href="#_sec.admin.monitoring.health"></a>2. Health Checking</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Although {kube}
takes care of a lot of the traditional deployment problems with its self-healing capabilities, it is considered good practice to monitor the availability and health of your services and applications to react to problems should they go beyond these automated measures.</p>
</div>
<div class="paragraph">
<p>A very basic (visual) health check can be achieved by accessing <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/#cadvisor">cAdvisor</a> on the admin node at port <code>4194</code>.
It will show a basic statistics UI about the cluster resources.</p>
</div>
<div class="paragraph">
<p>A complete set of instructions on how to monitor and maintain the health of you cluster is, however, beyond the scope of this document.</p>
</div>
<div class="paragraph">
<p>There are three levels of health checks.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cluster</p>
</li>
<li>
<p>Node</p>
</li>
<li>
<p>Application / Service</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_sec.admin.monitoring.health.cluster"><a class="anchor" href="#_sec.admin.monitoring.health.cluster"></a>2.1. Cluster Health Checks</h3>
<div class="paragraph">
<p>The basic check if a cluster is working correctly is based on a few criteria:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Are all services running as expected?</p>
</li>
<li>
<p>Is there at least one {kube} master fully working? Even if the deployment is configured to be highly available, it&#8217;s useful to know if <code>kube-controller-manager</code> is down on one of the machines.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Understanding cluster health</div>
<div class="paragraph">
<p>For further information consider reading <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/">Kubernetes:
     Troubleshoot Clusters</a></p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.health.cluster.kubernetes"><a class="anchor" href="#_sec.admin.monitoring.health.cluster.kubernetes"></a>2.1.1. {kube} master</h4>
<div class="paragraph">
<p>All components in {kube}
expose a <code>/healthz</code> endpoint.
The expected (healthy) response is a <code>200 HTTP</code> and a response body containing <code>ok</code>.</p>
</div>
<div class="paragraph">
<p>The minimal services for the master to work properly are:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">kube-apiserver</dt>
<dd>
<p>The component that receives your requests from <code class="command">kubectl</code> and from the rest of the {kube}
components.</p>
<div class="paragraph">
<p>Endpoint: <code>https://<code class="replaceable">MASTER NODE
FQDN</code>:6444/healthz</code> (HTTPS)</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``curl -i https://localhost:6444/healthz`` ok</pre>
</div>
</div>
</dd>
<dt class="hdlist1">kube-controller-manager</dt>
<dd>
<p>The component that contains the control loop, driving current state to the desired state.</p>
<div class="paragraph">
<p>Endpoint: <code>http://<code class="replaceable">MASTER NODE
FQDN</code>:10252/healthz</code> (HTTP)</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``curl -i http://localhost:10252/healthz`` ok</pre>
</div>
</div>
</dd>
<dt class="hdlist1">kube-scheduler</dt>
<dd>
<p>The component that schedules workloads to nodes.</p>
<div class="paragraph">
<p>Endpoint: <code>http://<code class="replaceable">MASTER NODE
FQDN</code>:10251/healthz</code> (HTTP)</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``curl -i http://localhost:10251/healthz`` ok</pre>
</div>
</div>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">High-Availability Environments</div>
<div class="paragraph">
<p>In a HA environment you can monitor <code>kube-apiserver</code> on <code>https://[replaceable]</code>MASTER NODE
      LOADBALANCER<code>:6443/healthz</code>.</p>
</div>
<div class="paragraph">
<p>If any master node is running correctly you will receive a valid response.</p>
</div>
<div class="paragraph">
<p>This does, however, not mean that all master nodes necessarily work correctly.
To ensure that all master nodes work properly, the health checks must be repeated individually for each master node deployed.</p>
</div>
<div class="paragraph">
<p>This endpoint will return a successful HTTP response if the cluster is operational; otherwise it will fail.
It will for example check that it can access <code>etcd</code> too.
This should not be used to infer that the overall cluster health is ideal.
It will return a a successful response even when only minimal operational cluster health exists.</p>
</div>
<div class="paragraph">
<p>To probe for full cluster health, you must perform individual health checking for all machines individually.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.cluster.health.etcd"><a class="anchor" href="#_sec.admin.monitoring.cluster.health.etcd"></a>2.1.2. ` etcd` Cluster</h4>
<div class="paragraph">
<p>Check that all machines that have the <code>etcd</code> role on the cluster see the etcd cluster as healthy.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``docker exec -it $(docker ps -q -f name="salt-master") salt -G 'roles:etcd' \
cmd.run 'set -a; source /etc/sysconfig/etcdctl; etcdctl cluster-health'`` f69e7af2880f42d68dca26ca892cb945:
    member af7ffa9bb1cb7c67 is healthy: got healthy result from https://caasp-master:2379
    member cc40a990d09b4705 is healthy: got healthy result from https://caasp-worker-1:2379
    member fe9b5ee9e1cc3cf7 is healthy: got healthy result from https://caasp-worker-2:2379
    cluster is healthy
ab040b25c2584bc8904971c0acbb250f:
    member af7ffa9bb1cb7c67 is healthy: got healthy result from https://caasp-master:2379
    member cc40a990d09b4705 is healthy: got healthy result from https://caasp-worker-1:2379
    member fe9b5ee9e1cc3cf7 is healthy: got healthy result from https://caasp-worker-2:2379
    cluster is healthy
63008aabc75b471b9a1aa2f64e4d30eb:
    member af7ffa9bb1cb7c67 is healthy: got healthy result from https://caasp-master:2379
    member cc40a990d09b4705 is healthy: got healthy result from https://caasp-worker-1:2379
    member fe9b5ee9e1cc3cf7 is healthy: got healthy result from https://caasp-worker-2:2379
    cluster is healthy</pre>
</div>
</div>
<div class="paragraph">
<p>More information on etcd cluster health can be found in <a href="#_sec.admin.nodes.graceful_shutdown.etcd">[_sec.admin.nodes.graceful_shutdown.etcd]</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.cluster.health.components"><a class="anchor" href="#_sec.admin.monitoring.cluster.health.components"></a>2.1.3. Running Components</h4>
<div class="paragraph">
<p>Check if the cluster has all required components running:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl cluster-info`` {kube}master is running at https://api.infra.caasp.local:6443
Dex is running at https://api.infra.caasp.local:6443/api/v1/namespaces/kube-system/services/dex:dex/proxy
KubeDNS is running at https://api.infra.caasp.local:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Tiller is running at https://api.infra.caasp.local:6443/api/v1/namespaces/kube-system/services/tiller:tiller/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</pre>
</div>
</div>
<div class="paragraph">
<p>You can optionally run <code class="command">kubectl cluster-info dump</code> to obtain a much more detailed output</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sec.admin.monitoring.health.node"><a class="anchor" href="#_sec.admin.monitoring.health.node"></a>2.2. Node Health Checks</h3>
<div class="paragraph">
<p>The basic check if a node is healthy consists of checking if <code>kubelet</code> and the CNI (Container Networking Interface) are working properly.</p>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.health.node.kubelet"><a class="anchor" href="#_sec.admin.monitoring.health.node.kubelet"></a>2.2.1. <code>kubelet</code></h4>
<div class="paragraph">
<p>Is the <code>kubelet</code> up and working in this node?</p>
</div>
<div class="paragraph">
<p>The <code>kubelet</code> has a port exposed <code>10250</code> on all machines; it&#8217;s possible to perform an HTTP request to the endpoint to find out if the kubelet is healthy on that machine.
The expected (healthy) response is a <code>200 HTTP</code> and a response body containing <code>ok</code>.</p>
</div>
<div class="paragraph">
<p>Endpoint: <code>https://<code class="replaceable">NODE</code>:10250/healthz</code> (HTTPS)</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``curl -i https://localhost:10250/healthz`` ok</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.health.node.cni"><a class="anchor" href="#_sec.admin.monitoring.health.node.cni"></a>2.2.2. ` CNI`</h4>
<div class="paragraph">
<p>Is CNI (Container Networking Interface) working as expected in this node? If not, <code>kube-dns</code> can not start.
Check if the <code>kube-dns</code> service is running.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>{prompt.user}``kubectl get deployments -n kube-system`` NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
dex             3         3         3            3           7d
kube-dns        3         3         3            3           7d
tiller-deploy   1         1         1            1           7d</pre>
</div>
</div>
<div class="paragraph">
<p>If kube-dns is running and you are able to create pods then you can be certain that CNI and your CNI plugin are working correctly.</p>
</div>
<div class="paragraph">
<p>There&#8217;s also the <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/">Monitor
     Node Health</a> check.
This is a <code>DaemonSet</code> that runs on every node, and reports to the <code>apiserver</code> back as <code>NodeCondition</code> and <code>Events</code>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sec.admin.monitoring.health.service"><a class="anchor" href="#_sec.admin.monitoring.health.service"></a>2.3. Service/Application Health Checks</h3>
<div class="paragraph">
<p>If the deployed services contain a health endpoint, or if they contain an endpoint that can be used to determine if the service is up, you can use <code>livenessProbes</code> and/or <code>readinessProbes</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Health check endpoints vs. functional endpoints</div>
<div class="paragraph">
<p>A proper health check is always preferred if designed correctly.</p>
</div>
<div class="paragraph">
<p>Despite the fact that any endpoint could potentially be used to infer if your application is up, a specific health endpoint in your application is preferred.
Such an endpoint will only respond affirmatively when all your setup code on the server has finished and the application is running in a desired state.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>livenessProbes</code> and <code>readinessProbes</code> share configuration options and probe types.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">initialDelaySeconds</dt>
<dd>
<p>Number of seconds to wait before performing the very first liveness probe.</p>
</dd>
<dt class="hdlist1">periodSeconds</dt>
<dd>
<p>Number of seconds that the kubelet should wait between liveness probes.</p>
</dd>
<dt class="hdlist1">successThreshold</dt>
<dd>
<p>Number of minimum consecutive successes for the probe to be considered successful (Default: 1).</p>
</dd>
<dt class="hdlist1">failureThreshold</dt>
<dd>
<p>Number of times this probe is allowed to fail in order to assume that the service is not responding (Default: 3).</p>
</dd>
<dt class="hdlist1">timeoutSeconds</dt>
<dd>
<p>Number of seconds after which the probe times out (Default: 1).</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>There are different options for the liveness probe to check:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Command</dt>
<dd>
<p>A command executed within a container; a retcode of 0 means success.</p>
<div class="paragraph">
<p>All other return codes mean failure.</p>
</div>
</dd>
<dt class="hdlist1">TCP</dt>
<dd>
<p>If a TCP connection can be established is considered success.</p>
</dd>
<dt class="hdlist1">HTTP</dt>
<dd>
<p>Any HTTP response between <code>200</code> and <code>400</code> indicates success.</p>
</dd>
</dl>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.health.service.livenessprobe"><a class="anchor" href="#_sec.admin.monitoring.health.service.livenessprobe"></a>2.3.1. livenessProbe</h4>
<div class="paragraph">
<p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/">livenessProbes</a> are used to detect running but misbehaving pods/a service that might be running (the process didn&#8217;t die), but that is not responding as expected.</p>
</div>
<div class="paragraph">
<p>Probes are executed by each <code>kubelet</code> against the pods that define them and that are running in that specific node.</p>
</div>
<div class="paragraph">
<p>When a <code>livenessProbe</code> fails, {kube}
 will automatically restart the pod and increase the <code>RESTARTS</code> count for that pod.</p>
</div>
<div class="paragraph">
<p>These probes will be executed every <code>periodSeconds</code> starting from <code>initialDelaySeconds</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sec.admin.monitoring.health.service.readinessprobe"><a class="anchor" href="#_sec.admin.monitoring.health.service.readinessprobe"></a>2.3.2. readinessProbe</h4>
<div class="paragraph">
<p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-readiness-probes">readinessProbes</a> are used to wait for processes that take some time to start.
Despite the container running, it might be performing some time consuming initializatoin operations.
During this time, you don&#8217;t want {kube}
 to route traffic to that specific pod; also, you don&#8217;t want that container to be restarted because it will appear unresponsive.</p>
</div>
<div class="paragraph">
<p>These probes will be executed every <code>periodSeconds</code> starting from <code>initialDelaySeconds</code> until the service is ready.</p>
</div>
<div class="paragraph">
<p>They support the same kind of probes as the <code>livenessProbe</code></p>
</div>
<div class="paragraph">
<p>Both probe types can be used at the same time.
The <code>livenessProbe</code> will ensure that if a service is running yet misbehaving, it will be restarted, and <code>readinessProbe</code> will ensure that {kube}
 won&#8217;t route traffic to that specific pod until it&#8217;s considered to be fully functional and running.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sec.admin.monitoring.health.general"><a class="anchor" href="#_sec.admin.monitoring.health.general"></a>2.4. General Health Checks</h3>
<div class="paragraph">
<p>We recommend to apply other best practices from system administration to your monitoring and health checking approach.
These steps are not specific to {productname}
and are beyond the scope of this document.
To simplify performing tasks like disk usage checks, you can use <code>salt</code>.
For more information see: <a href="#_sec.admin.salt">[_sec.admin.salt]</a></p>
</div>
</div>
</div>
</div>
</article>
  </main>
</div>
<footer class="footer">
  <p>Copyright (C) 2017-2018 <a href="https://opensource.suse.com/doc-susemanager/">SUSE Manager</a></p>
</footer>
<script src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<!-- fetched from https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js -->
<script>
function focusSearchInput () { document.querySelector('#search-input').focus() }
var search = docsearch({
  appId: 'KIB3CEDKWD',
  apiKey: '51646b7d454f125193a0ba62253e8e17',
  indexName: 'manager',
  inputSelector: '#search-input',
  autocompleteOptions: { hint: false, keyboardShortcuts: ['s'] },
  algoliaOptions: { hitsPerPage: 10 }
}).autocomplete;
search.on('autocomplete:closed', function () { search.autocomplete.setVal() });
focusSearchInput();
window.addEventListener('load', focusSearchInput)
</script>
<script src="../../../_/js/site.js"></script>
<script src="../../../_/js/vendor/highlight.js"></script>
<script>hljs.initHighlighting()</script>
  </body>
</html>
