[[_cha.admin.logging]]
= Logging
:doctype: book
:sectnums:
:toc: left
:icons: font
:experimental:
:sourcedir: .
:imagesdir: ./images
= Logging
:doctype: book
:sectnums:
:toc: left
:icons: font
:experimental:
:imagesdir: ./images

.Scope Of This Document
[IMPORTANT]
====
The scope of this document is limited to the {productname}
Infrastructure layer.
Logging the activity of deployed applications is beyond the scope of this document. 

Please refer to: https://kubernetes.io/docs/concepts/cluster-administration/logging/[Kubernetes:
   Logging Architecture] for more information. 

The {productname}
components run in indvidual Docker containers and typically you can get a set of log information using https://docs.docker.com/engine/reference/commandline/logs/#extended-description[docker-logs]. 

For detailed information on how to use log files for the individual components, please refer to the respective official documentation of the component. 
====

[[_sec.admin.logging.intro]]
== About {productname} Logging


Logging across the cluster is done on multiple logical levels.
You can think of them as three logical layers (simplified). 

* {productname} Infrastructure (Salt, Velum, LDAP) 
* Cluster (etcd, dex, tiller, kubernetes apiserver, kubernetes controller-manager, kubernetes scheduler) 
* Pod (kubelet, haproxy, flanneld, systemd, journald, dmesg) 


The individual log files allow introspection of activities across the cluster.
Due to some technical limitations it is sometimes not possible to directly trace log events from one layer to the next.
Most log files would be used for debugging purposes only. 

[[_sec.admin.logging.intro.log_levels]]
=== Log levels


There are two main components and their respective sub-components that allow configuration of different loglevels: Salt and {kube}
. 

* Salt 
** `salt-master`
** `salt-minion` on each machine 
* {kube}
** Master nodes 
*** `apiserver`
*** `controller-manager`
*** `scheduler`
** All nodes 
*** `kubelet`
*** `kube proxy`


[[_sec.admin.logging.admin]]
== Admin Node Logs

[[_sec.admin.logging.velum]]
=== {dashboard} Logs


The {dashboard}
logs will contain more details on error messages displayed in the dashboard. 

Logs are generated in the {dashboard}
container (``k8s_velum-dashboard``) running on the admin node. 

----
{prompt.user}``docker logs $(docker ps -q -f name="k8s_velum-dashboard")`` 
----

[[_sec.admin.logging.ldap]]
=== OpenLDAP Logs


The OpenLDAP logs contain information about the authentication of users in the {dashboard}
dashboard. 

The OpenLDAP logs are generated in the [path]``k8s_openldap_velum``
 container running on the admin node. 

----
{prompt.user}``docker logs $(docker ps -q -f name="k8s_openldap_velum")`` 
----

[[_sec.admin.logging.salt]]
== Salt Logging

`Salt` performs a variety of functions that control behavior and configuration of the {kube}
 cluster.
A failure of executing certain `Salt` workflows could lead to an unhealthy cluster, in such a case it can be inspected using `Salt` log information. 

Salt orchestration and master log are generated on the `Salt
   Master` container ([path]``k8s_salt-master``
) running on the admin node. 

Salt minion logs are generated in the respective salt minion containers on each node.
The `salt-master` collects these logs on the admin node and writes them into the MariaDB container [path]``k8s_velum-mariadb``
. 

[[_sec.admin.logging.salt.orchestration]]
=== Salt Orchestration Log


The `Salt` orchestration logs contains log entries about orchestration events that have changed the cluster. 

Orchestration events are: 

* Bootstrapping 
* Adding new nodes 
* Removing nodes 
* Updating settings 
* Upgrading a cluster 


----
{prompt.user}``/var/lib/supportutils-plugin-suse-caasp/debug-salt \
--json_output=events.txt \
--summary_output=events-summarized.txt \
--text-status \
--no-color`` 
----


Reading the [path]``events-summarized.txt``
 file should be enough for detecting most (if not all) of the issues caused by ``Salt``. 

[[_sec.admin.logging.salt.master]]
=== Salt Master Log


Retrieve the `salt-master` logs. 

----
{prompt.user}``docker exec -it $(docker ps -q -f name="salt-master") \
cat /var/log/salt/master`` 
----

[[_sec.admin.logging.salt.minion]]
=== Salt Minion Logs


Retrieve the `salt-minion` logs for all nodes.
This will show all output for all `salt-minions` at once.
Execute the following command on the admin node. 

Of course, it's possible to retrieve this information on any specific node by reading the [path]``/var/log/salt/minion``
 file. 

----
{prompt.user}``docker exec -it $(docker ps -q -f name="salt-master") \
salt '*' cmd.run "cat /var/log/salt/minion"`` 
----

[[_sec.admin.logging.log_levels.salt]]
=== Salt Log Levels


Salt provides different loglevels that apply both to the master and the minions. 

quiet::
Nothing should be logged at this level 

critical::
Critical errors 

error::
Errors 

warning::
Warnings 

info::
Normal log information 

profile::
Profiling information on salt performance 

debug::
Information useful for debugging both salt implementations and salt code 

trace::
More detailed code debugging information 

garbage::
Even more debugging information 

all::
Everything 


For detailed explanations of the usage of these log levels please see: https://docs.saltstack.com/en/latest/ref/configuration/logging/[Salt
    Log Levels (Upstream)]

[[_sec.admin.logging.log_levels.salt.set]]
==== Setting A Different Log Level


The `salt-master` configuration can be modified on the admin node, at [path]``/etc/caasp/salt-master-custom.conf``
.
Inside this file you can add: ``log_level: debug``. 

Note that after any change on this file you need to restart the `salt-master` container, like: 

----
``docker rm -f $(docker ps -q -f name="salt-master")`` .
----


After deleting this container, the `kubelet` will bring up a new `salt-master` container automatically with the new configuration applied.
Then.
you can check the logs with the `debug` loglevel. 

----
``docker logs -f $(docker ps -q -f name="salt-master")`` 
----

[[_sec.admin.logging.transactional_updates]]
== Transactional Update Log


The [command]``transactional-update`` method processes updates in the background and generates new machine image snapshots.
This process can run into issues.
Possible causes are connectivity issues or timeouts against the package repository.
In such cases the update fails and the affected node will be marked with a red cross in {dashboard}
. 

In most cases this situation resolves itself the next time the update process runs automatically.
If you have performed manual updates or must debug a failed update, you can read the log for [command]``transactional-update`` with the command below. 

The [command]``transactional-update`` logs are generated in the {mos}
 layer on each node respectively. 

For more information on transactional-update, see: <<_sec.admin.software.transactional_updates>>

----
{prompt.user}``docker exec -it $(docker ps -q -f name="salt-master") \
salt -P 'roles:(admin|kube-(master|minion)' \
cmd.run "journalctl -u transactional-update"`` 
----

[[_sec.admin.logging.kubernetes]]
== {kube} Audit Log


To track actions that have been performed on the cluster, you can enable the {kube}
audit log in {dashboard}
. 

Navigate to: menu:Settings → KUBERNETES → Auditing[]
.
This allows the audit logs to be written on the {kube}
 master nodes at [path]``/var/log/kube-apiserver/audit.log``
 and you can then use an external data collector like `fluentd` to collect all the audit logs. 

.Kubernetes Audit Log Documentation
[NOTE]
====
For more information on the audit log and its contents, see: https://v1-13.docs.kubernetes.io/docs/tasks/debug-application-cluster/audit/[Kubernetes
    Documentation: Auditing]
====

.{kube}Audit Log Limitations
[IMPORTANT]
====
The {kube}
audit log only collects and stores actions performed on the {kube}
level of the cluster.
This does not include any actions performed by {productname}
administrators in {dashboard}
or any of the resulting actions of services. 
====


image::velum_settings_audit.png[scaledwidth=100%]


Enable Auditing::
Enable / Disable the audit logging feature (Default: ``Disabled``) 

Max size::
Maximum size in megabytes of the audit log file before it gets rotated (Default: ``10``) 

Max age::
Maximum number of days to retain old audit log files (Default: ``15``) 

Max backup::
Maximum number of audit log files to retain (Default: ``20``) 

Policy::
The YAML file defining the https://v1-13.docs.kubernetes.io/docs/tasks/debug-application-cluster/audit/#audit-policy[auditing
policy rules]


[[_sec.admin.logging.log_levels.kubernetes]]
=== {kube} Log Levels


For {kube}
our default `loglevel` is `2` (https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-output-verbosity-and-debugging[Kubernetes
    Upstream: Output Verbosity and Debugging]). 

0::
Generally useful for this to ALWAYS be visible to an operator. 

1::
A reasonable default log level if you don't want verbosity. 

2::
Useful steady state information about the service and important log messages that may correlate to significant changes in the system.
This is the recommended default log level for most systems. 

3::
Extended information about changes. 

4::
Debug level verbosity. 

6::
Display requested resources. 

7::
Display HTTP request headers. 

8::
Display HTTP request contents. 


[[_sec.admin.logging.log_levels.kubernetes.set]]
==== Setting A Different Log Level

.Procedure: Modify {kube}Log Level Across The Cluster
. Change the log level value in the Salt pillar. 
+

----
{prompt.user}``docker exec -it $(docker ps -q -f name="dashboard") \
entrypoint.sh bundle exec rake "velum:create_pillar['kube_log_level', '4']"`` 
----
. Then run Salt orchestration to rebuild the configuration across the cluster. 
+

----
{prompt.user}``docker exec -it $(docker ps -q -f name="salt-master") \
salt-run state.orchestrate orch.kubernetes`` 
----


If modified, this setting will be applied to all {kube}
components; there is no way to set a different loglevel per component.
Moreover, there is no way to specify different loglevels per machine. 

[[_sec.admin.logging.fluentd]]
== External log collection


At {kube}
level, there are different solutions that can be implemented.
For example: https://docs.fluentd.org/v0.12/articles/kubernetes-fluentd[fluentd] can be used to collect all applications log in a central instance. 

Then, https://kubernetes.io/docs/tasks/debug-application-cluster/logging-elasticsearch-kibana/[Elasticsearch
   and Kibana] can be used to provide an intuitive way to visualize and interact with the logs. 