== Network Policies

The default behavior of {kube} is that all pods can see all other pods within a cluster, whether those pods are hosted by the same {kube} node or different ones.
This behavior is intentional, and aids greatly in the development process as the complexity of networking is effectively removed from both the developer and the operator.

However, when a workload is deployed in a {kube} cluster in production, any number of reasons may arise leading to the need to isolate some workloads from others.
For example, if a Human Resources department is running workloads processing PII (Personally Identifiable Information), those workloads should not by default be accessible by any other workload in the cluster.

Network policies are the mechanism provided by {kube} which allow a cloud operator to isolate workloads from each other in a variety of ways.
For example, a policy could be defined which only allows a database server workload to be accessed only by the web servers whose pages use the data in the database.
Another policy could be defined in the cluster which allows only web browsers outside the cluster to access the web server workloads in the cluster.

To implement network policies, a network plugin must be correctly integrated into the cluster.
{productname} incorporates Cilium as its supported network policy management plugin.
Cilium leverages BPF, an evolutionary step forward in high-performance kernel-based packet processing.
Packet processing is a low-level kernel function and its importance can’t be overstated. Every single byte communicated between {kube} pods transits through a packet processing engine, so the higher performance the packet processor is, the more workloads can be run on a cluster.
Put simply, technologies like link:https://www.kernel.org/doc/html/latest/bpf/index.html[BPF (Berkeley Packet Filter)] help maximize return on investment (ROI).
Other policy management plugins in the {kube} ecosystem leverage `iptables`, a very mature and stable software firewall.

{suse} has supported `iptables` since its inception in the Linux world, but believes BPF brings sufficiently compelling advantages over `iptables` to standardize on Cilium for policy management.

Not only does Cilium have performance benefits brought on by BPF, it also has benefits far higher in the network stack.
The most typically used policies in {kube} cover L3 and L4 events in the network stack, allowing workloads to be protected by specifying IP addresses and TCP ports.
To implement the earlier example using a layer three policy, a web server workload running at IP address `192.168.0.1` would be allowed to access a MySQL database workload running at IP address `192.168.0.2` on TCP port `3306`.

{productname} versions 4.0 and 4.1 support layer three and four policy management; the hyperlinks below will refer you to Cilium documentation on creating these policies, as Cilium documentation is an excellent and definitive source.

Versions of {productname} after 4.1 are slated to include layer seven policy management which will enable policies to be enforced on items like memcached verbs, gRPC methods, and Cassandra tables.
Since standard Linux `iptables` no longer incorporate L7 firewall functionality, SUSE is excited by the potential of providing our customers with the ability to enforce layer seven policies using Cilium.

Find below hyperlinks to Cilium’s documentation including a high-level introduction to Cilium technology as well as L3 and L4 protection using IP addresses and TCP ports or DNS addresses.

General introduction to Cilium::
https://cilium.readthedocs.io/en/v1.5/intro/

Securing traffic for HTTP servers and APIs::
https://cilium.readthedocs.io/en/v1.5/gettingstarted/http/

Restricting the network traffic to specific DNS queries or domains::
https://cilium.readthedocs.io/en/v1.5/gettingstarted/dns/
