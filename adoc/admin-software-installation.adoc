[[software-installation]]
= Software Installation

Software can be installed in three basic layers

Base OS layer::
Linux RPM packages, Kernel etc.. Installation via {ay},{tf} or {zypper}

{kube} Stack::
Software that helps/controls execution of workloads in {kube}

Container image::
Here it entirely depends on the actual makeup of the container what can be installed and how.
Please refer to your respecitve container image documentation for further details.
[NOTE]
Installation of software in container images is beyond the scope of this document.

== Base OS

Applications that will be deployed to {kube} will typically contain all the required software to be executed.
In some cases, especially when it comes to the hardware layer abstraction (storage backends, GPU), additional packages
must be installed on the underlying operating system outside of {kube}.

[NOTE]
====
The following examples show installation of required packages for `Ceph`, please adjust the list of
packages and repositories to whichever software you need to install.

While you can install any software package from the {sles} ecosystem this falls outside of the support scope for {productname}.
====

=== Initial Rollout

During the rollout of nodes you can use either {ay} or {tf} (depending on your chosen deployment type)
to automatically install packages to all nodes.

For example, to install additional packages required by the `Ceph` storage backend you can modify
your `autoyast.xml` or `tfvars.yml` files to include the additional repositories and instructions to
install `xfsprogs` and `ceph-common`.

. `tfvars.yml`
+
[source,yaml]
----
# EXAMPLE:
# repositories = {
#   repository1 = "http://example.my.repo.com/repository1/"
#   repository2 = "http://example.my.repo.com/repository2/"
# }
repositories = {
        ....
}

# Minimum required packages. Do not remove them.
# Feel free to add more packages
packages = [
  "kernel-default",
  "-kernel-default-base",
  "ca-certificates-suse",
  "xfsprogs",
  "ceph-common"
]
----
. `autoyast.xml`
+
[source,xml]
----
<!-- install required packages -->
<software>
  <image/>
  <products config:type="list">
    <product>SLES</product>
  </products>
  <instsource/>
  <patterns config:type="list">
    <pattern>base</pattern>
    <pattern>enhanced_base</pattern>
    <pattern>minimal_base</pattern>
    <pattern>basesystem</pattern>
  </patterns>
  <packages config:type="list">
    <package>ceph-common</package>
    <package>xfsprogs</package>
  </packages>
</software>
----

=== Existing Cluster

To install software on existing cluster nodes, you must use `zypper` on each node individually.
Simply log in to a node via SSH and run:

----
sudo zypper in ceph-common xfsprogs
----

== {kube} stack

[[helm_tiller_install]]
=== Installing Helm and Tiller

- As of {productname} {productversion},
Helm is part of the {productname} package repository, so to use this,
you only need to run the following command from the location where you normally run `skuba` commands:
+
[source,bash]
----
sudo zypper install helm
----

- As of {productname} {productversion}, Tiller is not part of the {productname} package repository,
so to install the Tiller server, choose either way to deploy the Tiller server:
* Insecure Tiller Deployment
+
[source,bash]
----
kubectl create serviceaccount --namespace kube-system tiller
kubectl create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller

helm init --tiller-image registry.suse.com/caasp/v4/helm-tiller:{helm_tiller_version} --service-account tiller
----

* Secure Tiller Deployment with SSL/TLS
+
. Prepare CA certificate
+
In some cases you want to create self-signed certificates for testing purpose. This is not recommended for the production environment. If you are using proper CA signed certificates or using existed {kube} cluster CA certificates, you could skip this step.
+
[source,bash]
----
openssl genrsa -out ca.key 2048
openssl req -key ca.key -new -x509 -days 3650 -sha256 -out ca.crt -extensions v3_ca
----

. Prepare Tiller server certificate
+
[source,bash]
----
openssl genrsa -out tiller.key 2048
openssl req -key tiller.key -new -sha256 -out tiller.csr
openssl x509 -req -CA ca.crt -CAkey ca.key -CAcreateserial -in tiller.csr -out tiller.crt -days 365
----

. Prepare Helm client certificate
+
[source,bash]
----
openssl genrsa -out helm.key 2048
openssl req -key helm.key -new -sha256 -out helm.csr
openssl x509 -req -CA ca.crt -CAkey ca.key -CAcreateserial -in helm.csr -out helm.crt -days 365
----

. Deploy Tiller server with SSL/TLS
+
[source,bash]
----
kubectl create serviceaccount --namespace kube-system tiller
kubectl create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller

helm init --tiller-tls --tiller-tls-verify --tiller-tls-cert tiller.crt --tiller-tls-key tiller.key --tls-ca-cert ca.crt --tiller-image registry.suse.com/caasp/v4/helm-tiller:{helm_tiller_version} --service-account tiller
----

. Configure Helm client with SSL/TLS
+
Setup $HELM_HOME environment and copy the CA certificate, helm client certificate and key to the $HELM_HOME path.
+
[source,bash]
----
export HELM_HOME=<path/to/helm/home>

cp ca.crt $HELM_HOME/ca.pem
cp helm.crt $HELM_HOME/cert.pem
cp helm.key $HELM_HOME/key.pem
----
+
Then, for the further helm command, pass flag `--tls`. For example:
[source,bash]
+
----
helm ls --tls [flags]
helm install --tls <CHART> [flags]
helm upgrade --tls <RELEASE_NAME> <CHART> [flags]
helm del --tls <RELEASE_NAME> [flags]
----

////
Note: When Helm is included in v4, Tiller server will be automatically installed after CaaS Platform setup.
So we probably  just need to mention that we use it and that it's installed automatically.
////
