<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha.deploy.upgrade"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Upgrading &productname;</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <para>
  As &productname; is constantly developed and improved, new versions get
  released. You are strongly advised to upgrade to a supported release. These
  upgrades may involve manual intervention.
 </para>
 <important>
  <title>Service Window Required</title>
  <para>
   Upgrades may take take some time, during which services may be degraded in
   pervormance or completely unavailable. Please make sure to plan a service
   window.
  </para>
 </important>
 <procedure xml:id="pro.deploy.upgrade.procedure">
  <title>General Upgrade Procedure</title>
  <step>
   <para>
    Upgrade the &admin_node;.
   </para>
  </step>
  <step>
   <para>
    Manually perform additional upgrade steps of the &admin_node;. These steps
    are version-specific and described in the following chapters.
   </para>
  </step>
  <step>
   <para>
    Upgrade the cluster nodes through &dashboard;.
   </para>
  </step>
 </procedure>

 <sect1 xml:id="sect.deploy.upgrade.caasp1">
  <title>Upgrading from &productname; 1</title>
  <para>
   The following sections contain the necessary steps to upgrade from
   &productname; 1 to 2 or later. <!-- Note that for later versions of
   &productname;, additional steps may be necesssary. These are described in
   their own version-specific sections. -->
  </para>
  <sect2 xml:id="sect.deploy.upgrade.caasp1.users">
   <title>Migrating Users</title>
   <para>
    &productname; 2 comes with Role-Based Access Control (RBAC), which stores
    user information in <phrase role="productname">OpenLDAP</phrase>. Therefore,
    after upgrading from &productname; 1 to version 2 or higher, you have to
    migrate existing &dashboard; users to <phrase
     role="productname">OpenLDAP</phrase> users.
   </para>
   <para>For more information about RBAC and user management, refer to <xref linkend="auth"/>.</para>
   <procedure xml:id="proc.deploy.upgrade.caasp1.users">
    <title>Migrating users from version 1 to 2</title>
    <step>
     <para>
      Connect to the &admin_node; using SSH.
     </para>
    </step>
    <step>
     <para>
      Run the command:
     </para>
<screen>&prompt.root;<command>docker</command> <option>exec -it</option> $(<command>docker</command> <option>ps</option> | <command>grep</command> <option>dashboard</option> | <command>awk</command> <option>'{print $1}')</option> \
    <command>entrypoint.sh</command> <option>bundle exec rake velum:migrate_users</option></screen>
    </step>
   </procedure>
   <para>After running this command, existing user accounts will be available
    for logging into &dashboard; again.</para>
  </sect2>
  <sect2 xml:id="sect.deploy.upgrade.caasp1.etcd">
   <title>Upgrading etcd</title>
   <para>
    &productname; 2 comes with &kube; 1.7, which uses <literal>etcd</literal>
    version 3 as default storage backend. Therefore, after upgrading from
    &productname; 1 to version 2 or higher, you have to orchestrate the
    migration between <literal>etcd</literal> 2 and 3.
   </para>
   <para>
    The orchestration will shutdown all <literal>etcd</literal> and
    <literal>kube-api</literal> services, perform the <literal>etcd</literal>
    migration steps, set the <quote>etcd_version = etcd3</quote> pillar value,
    and restart <literal>etcd</literal> and <literal>kube-api</literal>.
   </para>

   <important>
    <title>Service Window Required</title>
    <para>
     This migration can take a several minutes, during which
     <literal>etcd</literal> and <literal>kube-api</literal> services are
     unavailable. Please make sure to plan a service window.
    </para>
   </important>

   <procedure xml:id="proc.deploy.upgrade.caasp1.etcd">
    <title>Migrating from etcd version 2 to 3</title>
    <step>
     <para>
      Connect to the &admin_node; using SSH.
     </para>
    </step>
    <step>
     <para>
      Run the command:
     </para>
<screen>&prompt.root;<command>docker</command> <option>exec -it</option> $(<command>docker</command> <option>ps</option> | <command>grep</command> <option>salt-master</option> | <command>cut</command> <option>-d" " -f1</option>) \
    <command>salt-run</command> <option>state.orchestrate orch.etcd-migrate</option></screen>
    </step>
   </procedure>
   <para>
    After the command successfully finished, all services will be available
    again.
   </para>
  </sect2>
  <sect2>
   <title>Adding new settings</title>
   <para>
    Run the following commands to ensure that default values are set correctly
    for some new options introduced in &productname; 2 which were not present
    in version 1.
   </para>
   <procedure xml:id="proc.deploy.upgrade.caasp1.settings">
    <title>Add new settings introduced in &productname; 2</title>
    <step>
     <para>
      Connect to the &admin_node; using SSH.
     </para>
    </step>
    <step>
     <para>
      Run the command:
     </para>
<screen>&prompt.root;<command>docker</command> <option>exec -it</option> $(<command>docker</command> <option>ps</option> | <command>grep</command> <option>dashboard</option> | <command>awk</command> <option>'{print $1}')</option> \
    <command>bash</command></screen>
    </step>
    <step>
     <para>
      Now set <literal>dashboard_external_fqdn</literal> to the FQDN of the
      &admin_node; host:
     </para>
<screen><command>entrypoint.sh</command> <option>bundle exec rails runner \
    'Pillar.create(pillar: "dashboard_external_fqdn", value: "<replaceable>FQDN</replaceable>")'</option></screen>
     <para>
      Note well: <literal>FQDN</literal>FQDN corresponds to the Fully
      Qualified Domain Name of your &admin_node; host.
     </para>
    </step>
    <step>
     <para>
      While you have the console session open, create the LDAP related pillars:
     </para>
<screen>$ entrypoint.sh bundle exec rails runner \
'Velum::LDAP.ldap_pillar_settings!({}).each {|key, value| Pillar.create(pillar: Pillar.all_pillars[key.to_sym], value: value)}'</screen>
    </step>
    <step>
     <para>
      If you intend to use Helm on your CaaSP Cluster, you also need to enable
      Tiller (Helm's server component). From the save console used before,
      execute the following command:
     </para>
<screen>$ entrypoint.sh bundle exec rails runner \
    'Pillar.create(pillar: "addons:tiller", value: "true")'</screen>
    </step>
    <step>
     <para>Exit the &dashboard; container by pressing Ctrl+D.</para>
    </step>
   </procedure>
  </sect2>
  <sect2 xml:id="sect.deploy.upgrade.caasp1.sa">
   <title>Generating the the sa.key File on the CA</title>
   <para>
    <!-- cwickert 2018-01-18: TODO Explain what we are doing here -->
   </para>
   <procedure>
    <title>Generate the sa.key file on the CA</title>
    <step>
     <para>
      Connect to the &admin_node; using SSH.
     </para>
    </step>
    <step>
     <para>
      Run the command:
     </para>
<screen>&prompt.root;<command>docker</command> <option>exec -it</option> $(<command>docker</command> <option>ps</option> | <command>grep</command> <option>salt-master</option> | <command>awk</command> <option>'{print $1}')</option> \
    <command>bash</command></screen>
     <para>
      This will give you a shell in the &salt; master container.
     </para>
    </step>
    <step>
     <para>
      From that console execute the following command:
     </para>
<screen>$ salt "ca" state.apply kubernetes-common.generate-serviceaccount-key</screen>
    </step>
    <step>
     <para>
      Exit the &salt; master container by pressing Ctrl+D.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
</chapter>
